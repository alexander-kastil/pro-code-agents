# Implementing Agents and Copilots using Azure AI Studio, Semantic Kernel and Microsoft AutoGen

This workshop is designed to help you develop AI Agents and Copilots using Azure AI Studio, Semantic Kernel and Microsoft AutoGen. The workshop is divided into four modules, each covering different aspects of developing AI solutions with Azure OpenAI. It bundles, deepens and prepares for the following Microsoft Applied Skills:

- AI-3016 - Develop custom copilots with Azure AI Studio
- AI-2005 - Develop AI Agents using Azure OpenAI and the Semantic Kernel SDK

Module 1: Develop custom Copilots with Azure AI Studio

This module provides an introduction to Azure AI Studio, highlighting its core features, capabilities, and use cases. It explains how to build a RAG-based copilot solution with your own data, and the basics of developing copilots with Prompt Flow. The module covers integrating a fine-tuned language model with your copilot and evaluating its performance. It emphasizes the importance of understanding the development lifecycle and using LangChain in Prompt Flow.

Module 2: Develop AI agents using Azure OpenAI and the Semantic Kernel SDK

This module focuses on building AI agents using the Semantic Kernel SDK, starting with understanding the purpose of Semantic Kernel and effective prompting techniques. It explains how to give AI agents skills using Native Functions and create plugins for Semantic Kernel. The module also covers providing state and history using Kernel Memory, using intelligent planners, and integrating various AI services with Semantic Kernel. Additionally, it discusses implementing copilots and agents, completing multi-step tasks, and using personas with agents.

Module 3: Monitoring & Deploying LLM Applications

This module outlines the deployment process for LLM applications, including introductions to Azure Container Apps and how to deploy LLM applications to them. It explains how to scale Azure OpenAI for .NET chat using RAG with Azure Container Apps and manage dynamic sessions with LangChain. The module also covers exposing LLM apps using Azure API Management and monitoring and managing LLM applications to ensure optimal performance.

## Module 1: Develop custom Copilots with Azure AI Studio

### Introduction to Azure AI Studio & AI Agents

- Core Features and Capabilities of Azure AI Studio
- Azure AI Hubs & Projects
- Provision and manage an Azure AI Resources
- Azure AI Studio: Use Cases and Scenarios
- Characteristics of AI Agents 
- Single AI Agent vs Multi-Agent Systems
- Semantic Kernel vs AutoGen

# Explore and deploy models from the model catalog in Azure AI Studio

- Explore & Deploy Models from the Model Catalog
- Improve the performance of a language model

## Apply prompt engineering with Azure OpenAI Service

- Understand prompt engineering
- Write more effective prompts
- Zero-shot- vs Few-shot learning
- Chain-of-thought prompting 
- Provide context to improve accuracy
- System Messages
- Function Calling

# Get started with Prompt Flow to develop language model apps in the Azure AI Studio

- Development Lifecycle of LLM Applications
- Understand core Components of Prompt Flow and Flow Types
- Explore Connections and runtimes
- Explore variants and monitoring options

### Build a RAG-based copilot solution with your own data using Azure AI Studio

- Ground your language model with Retrieval Augmented Generation (RAG)
- Index your data with Azure AI Search to make it searchable for language models
- Build a copilot using RAG on your own data in the Azure AI Studio
- Using RAG in Prompt Flow

## Integrate a fine-tuned language model with your copilot in the Azure AI Studio

- Fine Tuning Overview 
- When to use fine-tuning
- Prepare your data for fine-tuning
- Fine-tune a language model in the Azure AI Studio

### Evaluate the performance of you custom copilot in the Azure AI Studio

- Assess the model performance
- Understand model benchmarks
- Using evaluations to monitor and improve your model

# Fundamentals of Responsible Generative AI

- Plan a responsible generative AI solution
- Identify potential harms
- Measure potential harms
- Mitigate potential harms
- Operate a responsible generative AI solution

## Module 2: Develop AI Agents using Azure OpenAI and the Semantic Kernel SDK

### Build your kernel

- Understand the purpose of Semantic Kernel
- Understand prompting basics & techniques for more effective prompts
- Use OpenAI, Azure OpenAI & 3rd party Large Language Models

### Give your AI agent skills using Native Functions

- Understand Native Functions in the Semantic Kernel SDK
- Implement Native Functions using Prompts
- Using yaml based prompts
- Chaining Native Functions
- Using Pre- and Post Hooks

### Create Plugins for Semantic Kernel

- Understand the purpose of Semantic Kernel plugins
- Built-in plugins (ConversationSummary, FileIO, Http, Math, Time)
- Implementing data retrieval and task automation plugins
- Persisting Data using Plugins

### Providing state & history using Kernel Memory

- Understand the purpose of Kernel Memory 
- Semantic Kernel Memory: In-process & Connectors
- High performance memory using Azure Cosmos DB DiskANN
- Kernel Memory & Retrieval Augmented Generation (RAG)
- Streaming Responses to Single Page Applications

### Use intelligent planners

- Understand planners in the Semantic Kernel SDK
- Use & optimize planners to automate function calls
- Learn how to use Semantic Kernel SDK to automatically invoke functions
- Function calling as a planner replacement
- Automatic vs Manual Function Calling
- Using Function Filters and Function Calling Helpers

### Integrating AI Services with Semantic Kernel

- Text to Image & Image to Text
- Using Audio to Text
- Using Hugging Face with Semantic Kernel
- Integrating Prompt-Flow with Semantic Kernel

### Implementing Copilots & Assistant using Semantic Kernel

- Assistant Overview
- OpenAI Assistant Specification
- Completing multi-step tasks with Assistant
- Using Personas with Assistant
- Implementing Multi Assistant Solutions

## Module 3: Implement multi-agent solution using Microsoft AutoGen

- Introduction to Microsoft AutoGen
- 

## Module 4: Monitoring & Deploying LLM Applications

- Understand the deployment process for LLM applications
- Introductions to Azure Container Apps
- Deploy LLM applications to Azure Container Apps
- Scale Azure OpenAI Apps with Azure Container Apps
- Azure Container Apps Dynamic Sessions
- Monitor and manage LLM applications