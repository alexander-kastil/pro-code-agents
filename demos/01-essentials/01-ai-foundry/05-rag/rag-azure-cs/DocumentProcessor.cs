using System.Text.Json;
using Azure.AI.Inference;
using Azure.AI.OpenAI;
using Azure.Storage.Blobs;

namespace RagAzure;

public class DocumentProcessor
{
    private readonly AzureConfiguration _config;

    public DocumentProcessor(AzureConfiguration config)
    {
        _config = config;
    }

    public async Task<List<SearchDocument>> RetrieveAndProcessDocumentsAsync(
        BlobServiceClient blobServiceClient,
        object embeddingsClient,
        string containerName,
        string blobName)
    {
        Console.WriteLine("\n## 4. Document Retrieval and Processing");
        Console.WriteLine("‚úÖ Document processors initialized");
        
        Console.WriteLine("\n## 5. Retrieve and Process Documents");
        Console.WriteLine(new string('=', 60));
        Console.WriteLine("üì• RETRIEVING PROCESSED DOCUMENTS FROM BLOB STORAGE");
        Console.WriteLine(new string('=', 60));
        
        var containerClient = blobServiceClient.GetBlobContainerClient(containerName);
        var blobClient = containerClient.GetBlobClient(blobName);
        
        if (!await blobClient.ExistsAsync())
        {
            Console.WriteLine($"‚ùå Blob not found: {blobName}");
            return new List<SearchDocument>();
        }
        
        var download = await blobClient.DownloadContentAsync();
        var jsonContent = download.Value.Content.ToString();
        
        var processedDocuments = JsonSerializer.Deserialize<ProcessedDocumentsWrapper>(jsonContent);
        
        if (processedDocuments?.Policies == null || processedDocuments.Policies.Count == 0)
        {
            Console.WriteLine("‚ùå No policy documents were found in the processed dataset.");
            return new List<SearchDocument>();
        }
        
        Console.WriteLine($"\nüéâ SUCCESS! Retrieved processed documents from blob storage");
        Console.WriteLine($"üìÑ Found {processedDocuments.Policies.Count} policy documents");
        
        var chunker = new TextChunker(_config.ChunkSize, _config.ChunkOverlap);
        var searchDocuments = new List<SearchDocument>();
        
        Console.WriteLine($"\nüìÇ Processing policies documents...");
        var successfulDocs = processedDocuments.Policies.Where(d => d.Success).ToList();
        Console.WriteLine($"‚úÖ Processing {successfulDocs.Count} successful policies documents");
        
        foreach (var doc in successfulDocs)
        {
            if (string.IsNullOrWhiteSpace(doc.Text))
            {
                Console.WriteLine($"‚ö†Ô∏è Skipping document with no text content: {doc.Metadata?.FileName ?? "Unknown"}");
                continue;
            }
            
            var metadata = new Dictionary<string, string>
            {
                ["category"] = "policies",
                ["file_name"] = doc.Metadata?.FileName ?? "Unknown",
                ["file_type"] = doc.Metadata?.FileType ?? "markdown"
            };
            
            var chunks = chunker.ChunkTextForSearch(doc.Text, metadata);
            
            foreach (var chunk in chunks)
            {
                try
                {
                    var embedding = await GenerateEmbeddingAsync(embeddingsClient, chunk.Content);
                    
                    var searchDoc = new SearchDocument
                    {
                        Id = Guid.NewGuid().ToString(),
                        Title = $"{metadata["file_name"]} - Part {chunk.ChunkId + 1}",
                        Content = chunk.Content,
                        Category = "policies",
                        FileName = metadata["file_name"],
                        FileType = metadata["file_type"],
                        ChunkId = chunk.ChunkId,
                        ChunkCount = chunk.ChunkCount,
                        OriginalLength = doc.Text.Length,
                        ChunkLength = chunk.Content.Length,
                        ProcessingDate = DateTimeOffset.UtcNow,
                        ContentVector = embedding
                    };
                    
                    searchDocuments.Add(searchDoc);
                }
                catch (Exception ex)
                {
                    Console.WriteLine($"‚ö†Ô∏è Failed to generate embedding for chunk {chunk.ChunkId} of {metadata["file_name"]}: {ex.Message}");
                }
            }
        }
        
        Console.WriteLine($"\n‚úÖ Prepared {searchDocuments.Count} policy document chunks for search index");
        
        if (searchDocuments.Count > 0)
        {
            var totalFiles = searchDocuments.Select(d => d.FileName).Distinct().Count();
            var totalChunks = searchDocuments.Count;
            var avgChunkLength = searchDocuments.Average(d => d.ChunkLength);
            
            Console.WriteLine($"\nüìä POLICIES INDEXING SUMMARY:");
            Console.WriteLine($"   üìÑ Total policy files: {totalFiles}");
            Console.WriteLine($"   üóÇÔ∏è Total chunks created: {totalChunks}");
            Console.WriteLine($"   üìè Average chunk length: {avgChunkLength:F0} characters");
            
            var fileStats = searchDocuments.GroupBy(d => d.FileName)
                .Select(g => new { FileName = g.Key, Count = g.Count() });
            
            Console.WriteLine($"\nüìã Policy files breakdown:");
            foreach (var stat in fileStats)
            {
                Console.WriteLine($"   ‚Ä¢ {stat.FileName}: {stat.Count} chunks");
            }
        }
        
        return searchDocuments;
    }

    private async Task<float[]> GenerateEmbeddingAsync(object client, string text)
    {
        if (client is AzureOpenAIClient openAIClient)
        {
            var embeddingClient = openAIClient.GetEmbeddingClient(_config.EmbeddingsModel);
            var result = await embeddingClient.GenerateEmbeddingAsync(text);
            return result.Value.ToFloats().ToArray();
        }
        else if (client is EmbeddingsClient inferenceClient)
        {
            var embeddingsOptions = new EmbeddingsOptions(new[] { text });
            var result = await inferenceClient.EmbedAsync(embeddingsOptions);
            // The Embedding is BinaryData that needs to be deserialized to float[]
            var embeddingData = result.Value.Data[0].Embedding;
            return embeddingData.ToObjectFromJson<float[]>() ?? Array.Empty<float>();
        }
        else
        {
            throw new InvalidOperationException("Unknown embeddings client type");
        }
    }
}

public class ProcessedDocumentsWrapper
{
    public List<ProcessedDocument> Policies { get; set; } = new();
}

public class ProcessedDocument
{
    public string Text { get; set; } = string.Empty;
    public bool Success { get; set; }
    public DocumentMetadata? Metadata { get; set; }
}

public class DocumentMetadata
{
    public string FileName { get; set; } = string.Empty;
    public string FileType { get; set; } = string.Empty;
}

public class SearchDocument
{
    public string Id { get; set; } = string.Empty;
    public string Title { get; set; } = string.Empty;
    public string Content { get; set; } = string.Empty;
    public string Category { get; set; } = string.Empty;
    public string FileName { get; set; } = string.Empty;
    public string FileType { get; set; } = string.Empty;
    public int ChunkId { get; set; }
    public int ChunkCount { get; set; }
    public int OriginalLength { get; set; }
    public int ChunkLength { get; set; }
    public DateTimeOffset ProcessingDate { get; set; }
    public float[] ContentVector { get; set; } = Array.Empty<float>();
}
