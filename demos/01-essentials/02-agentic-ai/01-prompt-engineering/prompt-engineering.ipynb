{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering for Agentic AI\n",
    "\n",
    "This notebook demonstrates prompt engineering techniques for working with agentic AI models. We'll explore different strategies to optimize how we communicate with AI models to achieve desired outcomes.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Introduction to Prompt Engineering](#introduction)\n",
    "2. [Environment Setup](#setup)\n",
    "3. [Basic Prompt Structures](#basic-structures)\n",
    "4. [Prompt Refinement Techniques](#refinement)\n",
    "5. [Chain of Thought Prompting](#chain-of-thought)\n",
    "6. [Advanced Patterns](#advanced-patterns)\n",
    "7. [Summary and Best Practices](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to Prompt Engineering <a id=\"introduction\"></a>\n",
    "\n",
    "### What is Prompt Engineering?\n",
    "\n",
    "Prompt engineering is the practice of designing and optimizing inputs (prompts) to AI language models to elicit desired responses. It's crucial for:\n",
    "\n",
    "- **Accuracy**: Getting precise and relevant answers\n",
    "- **Consistency**: Ensuring reliable outputs across similar queries\n",
    "- **Control**: Directing the model's behavior and output format\n",
    "- **Efficiency**: Reducing the need for multiple iterations\n",
    "\n",
    "### Why It Matters for Agentic AI\n",
    "\n",
    "In agentic AI systems, prompts serve as the primary interface for:\n",
    "- Defining agent roles and behaviors\n",
    "- Controlling task execution\n",
    "- Managing multi-turn conversations\n",
    "- Coordinating multiple agents\n",
    "\n",
    "Well-crafted prompts can significantly improve agent performance, reliability, and user experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Environment Setup <a id=\"setup\"></a>\n",
    "\n",
    "First, let's set up our connection to Azure AI Foundry. Make sure you have:\n",
    "1. Copied `.env.copy` to `.env`\n",
    "2. Updated the values with your Azure AI project details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Azure AI Foundry\n",
      "Using model: gpt-4.1-mini\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the AI Project client\n",
    "project_client = AIProjectClient(\n",
    "    endpoint=os.environ[\"PROJECT_ENDPOINT\"],\n",
    "    credential=DefaultAzureCredential()\n",
    ")\n",
    "\n",
    "# Get the OpenAI client\n",
    "chat = project_client.get_openai_client()\n",
    "model = os.environ[\"MODEL\"]\n",
    "\n",
    "print(f\"Connected to Azure AI Foundry\")\n",
    "print(f\"Using model: {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Helper function to display responses\n",
    "def get_completion(messages, temperature=0.7, max_tokens=500):\n",
    "    \"\"\"Helper function to get completions from the model\"\"\"\n",
    "    response = chat.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def display_comparison(prompt1, prompt2, label1=\"Prompt 1\", label2=\"Prompt 2\"):\n",
    "    \"\"\"Display side-by-side comparison of two prompts and their responses\"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\n{label1}:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Prompt: {prompt1[0]['content'] if isinstance(prompt1[0], dict) else prompt1}\")\n",
    "    response1 = get_completion(prompt1 if isinstance(prompt1[0], dict) else [{\"role\": \"user\", \"content\": prompt1}])\n",
    "    print(f\"\\nResponse:\\n{response1}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"\\n{label2}:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Prompt: {prompt2[0]['content'] if isinstance(prompt2[0], dict) else prompt2}\")\n",
    "    response2 = get_completion(prompt2 if isinstance(prompt2[0], dict) else [{\"role\": \"user\", \"content\": prompt2}])\n",
    "    print(f\"\\nResponse:\\n{response2}\")\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "print(\"Helper functions loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Prompt Structures <a id=\"basic-structures\"></a>\n",
    "\n",
    "Let's explore how different prompt structures affect model responses.\n",
    "\n",
    "### 3.1 Vague vs. Specific Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "\n",
      "Vague Prompt:\n",
      "--------------------------------------------------------------------------------\n",
      "Prompt: Tell me about Python.\n",
      "\n",
      "Response:\n",
      "Python is a high-level, interpreted programming language known for its readability, simplicity, and versatility. It was created by Guido van Rossum and first released in 1991. Python's design philosophy emphasizes code readability and a syntax that allows programmers to express concepts in fewer lines of code compared to languages like C++ or Java.\n",
      "\n",
      "Key features of Python include:\n",
      "\n",
      "1. **Easy to Learn and Use**: Python has a simple syntax similar to English, which makes it accessible to beginners.\n",
      "2. **Interpreted Language**: Python code is executed line-by-line, which makes debugging easier.\n",
      "3. **Dynamic Typing**: Variable types are determined at runtime, allowing for flexible coding.\n",
      "4. **Extensive Standard Library**: Python comes with a large standard library that supports many common programming tasks such as file I/O, system calls, and internet protocols.\n",
      "5. **Cross-Platform**: Python runs on various operating systems including Windows, macOS, Linux, and more.\n",
      "6. **Support for Multiple Programming Paradigms**: Python supports procedural, object-oriented, and functional programming styles.\n",
      "7. **Large Ecosystem and Community**: There are numerous third-party libraries and frameworks available for web development (Django, Flask), data analysis (Pandas, NumPy), machine learning (TensorFlow, scikit-learn), automation, and more.\n",
      "\n",
      "Python is widely used in many fields, including web development, data science, artificial intelligence, scientific computing, automation, and education. Its combination of simplicity and power makes it one of the most popular programming languages in the world.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Specific Prompt:\n",
      "--------------------------------------------------------------------------------\n",
      "Prompt: Explain Python's list comprehension feature. \n",
      "Include:\n",
      "1. A brief definition\n",
      "2. Basic syntax\n",
      "3. One practical example\n",
      "Keep your response under 150 words.\n",
      "\n",
      "Response:\n",
      "Python's list comprehension is a concise way to create lists by embedding a for-loop and optional conditionals within square brackets. It improves readability and reduces code lines.\n",
      "\n",
      "**Basic syntax:**  \n",
      "```python\n",
      "[expression for item in iterable if condition]\n",
      "```\n",
      "\n",
      "- *expression*: value to include in the new list  \n",
      "- *item*: variable representing each element  \n",
      "- *iterable*: collection being looped over  \n",
      "- *condition* (optional): filters items  \n",
      "\n",
      "**Example:** Create a list of squares for even numbers from 0 to 9:  \n",
      "```python\n",
      "squares = [x**2 for x in range(10) if x % 2 == 0]\n",
      "print(squares)  # Output: [0, 4, 16, 36, 64]\n",
      "```\n",
      "\n",
      "This generates a list by squaring only even numbers within the specified range.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Vague prompt\n",
    "vague_prompt = \"Tell me about Python.\"\n",
    "\n",
    "# Specific prompt\n",
    "specific_prompt = \"\"\"Explain Python's list comprehension feature. \n",
    "Include:\n",
    "1. A brief definition\n",
    "2. Basic syntax\n",
    "3. One practical example\n",
    "Keep your response under 150 words.\"\"\"\n",
    "\n",
    "display_comparison(vague_prompt, specific_prompt, \"Vague Prompt\", \"Specific Prompt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Takeaway**: Specific prompts with clear instructions and constraints produce more focused and useful responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Role-Based Prompting\n",
    "\n",
    "Assigning a role to the AI can significantly influence its response style and content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No role assignment\n",
    "no_role = [\n",
    "    {\"role\": \"user\", \"content\": \"How should I structure my code for a web application?\"}\n",
    "]\n",
    "\n",
    "# With role assignment\n",
    "with_role = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a senior software architect with 15 years of experience in scalable web application design. Provide practical, industry-standard advice.\"},\n",
    "    {\"role\": \"user\", \"content\": \"How should I structure my code for a web application?\"}\n",
    "]\n",
    "\n",
    "print(\"No Role Assignment:\")\n",
    "print(\"-\" * 80)\n",
    "response1 = get_completion(no_role)\n",
    "print(response1)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"\\nWith Role Assignment (Senior Software Architect):\")\n",
    "print(\"-\" * 80)\n",
    "response2 = get_completion(with_role)\n",
    "print(response2)\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Takeaway**: Role-based prompting helps set context, expertise level, and response style. The system message defines the AI's persona and behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Output Format Control\n",
    "\n",
    "You can control the structure and format of responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unstructured request\n",
    "unstructured = \"List the benefits of using microservices architecture.\"\n",
    "\n",
    "# Structured request\n",
    "structured = \"\"\"List the benefits of using microservices architecture.\n",
    "Format your response as:\n",
    "- Exactly 5 benefits\n",
    "- Each benefit as a heading followed by a 1-sentence explanation\n",
    "- Use numbered list format (1., 2., etc.)\n",
    "\"\"\"\n",
    "\n",
    "display_comparison(unstructured, structured, \"Unstructured Format\", \"Structured Format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Takeaway**: Explicitly specifying output format ensures consistency and makes responses easier to parse and use in applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prompt Refinement Techniques <a id=\"refinement\"></a>\n",
    "\n",
    "Let's explore techniques to refine prompts for better results.\n",
    "\n",
    "### 4.1 Adding Context and Examples (Few-Shot Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-shot (no examples)\n",
    "zero_shot = [\n",
    "    {\"role\": \"user\", \"content\": \"Classify the sentiment: 'This movie was absolutely terrible and I want my money back.'\"}\n",
    "]\n",
    "\n",
    "# Few-shot (with examples)\n",
    "few_shot = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a sentiment classifier. Classify text as POSITIVE, NEGATIVE, or NEUTRAL.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Classify: 'I love this product!'\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"POSITIVE\"},\n",
    "    {\"role\": \"user\", \"content\": \"Classify: 'The weather is okay.'\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"NEUTRAL\"},\n",
    "    {\"role\": \"user\", \"content\": \"Classify: 'This movie was absolutely terrible and I want my money back.'\"}\n",
    "]\n",
    "\n",
    "print(\"Zero-Shot Approach:\")\n",
    "print(\"-\" * 80)\n",
    "response1 = get_completion(zero_shot)\n",
    "print(response1)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"\\nFew-Shot Approach (with examples):\")\n",
    "print(\"-\" * 80)\n",
    "response2 = get_completion(few_shot)\n",
    "print(response2)\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Takeaway**: Providing examples (few-shot learning) helps the model understand the expected output format and style, leading to more consistent results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Using Delimiters and Structure\n",
    "\n",
    "Clear delimiters help the model distinguish between instructions and content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without delimiters\n",
    "without_delimiters = \"\"\"Summarize the following text in one sentence: \n",
    "The quick brown fox jumps over the lazy dog. This sentence contains every letter of the alphabet. \n",
    "It's commonly used as a typing test.\"\"\"\n",
    "\n",
    "# With delimiters\n",
    "with_delimiters = \"\"\"Summarize the text delimited by triple backticks in one sentence.\n",
    "\n",
    "Text: ```\n",
    "The quick brown fox jumps over the lazy dog. This sentence contains every letter of the alphabet. \n",
    "It's commonly used as a typing test.\n",
    "```\n",
    "\n",
    "Summary:\"\"\"\n",
    "\n",
    "display_comparison(without_delimiters, with_delimiters, \"Without Delimiters\", \"With Delimiters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Takeaway**: Delimiters (```, ---, ###, etc.) help separate instructions from content, reducing ambiguity and improving accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Temperature Control for Creativity vs. Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Write a creative tagline for a coffee shop that specializes in artisanal brews.\"\n",
    "\n",
    "print(\"Low Temperature (0.2) - More Focused and Deterministic:\")\n",
    "print(\"-\" * 80)\n",
    "response_low = get_completion([{\"role\": \"user\", \"content\": prompt}], temperature=0.2)\n",
    "print(response_low)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"\\nMedium Temperature (0.7) - Balanced:\")\n",
    "print(\"-\" * 80)\n",
    "response_med = get_completion([{\"role\": \"user\", \"content\": prompt}], temperature=0.7)\n",
    "print(response_med)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"\\nHigh Temperature (1.2) - More Creative and Random:\")\n",
    "print(\"-\" * 80)\n",
    "response_high = get_completion([{\"role\": \"user\", \"content\": prompt}], temperature=1.2)\n",
    "print(response_high)\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Takeaway**: \n",
    "- **Low temperature (0-0.3)**: Use for factual, consistent, and deterministic outputs\n",
    "- **Medium temperature (0.5-0.8)**: Balanced approach for most use cases\n",
    "- **High temperature (0.9-1.5)**: Use for creative, diverse outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Chain of Thought Prompting <a id=\"chain-of-thought\"></a>\n",
    "\n",
    "Chain of thought (CoT) prompting encourages the model to break down complex problems into steps, improving reasoning accuracy.\n",
    "\n",
    "### 5.1 Basic Chain of Thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without chain of thought\n",
    "direct_prompt = \"\"\"A store sells apples for $2 each and oranges for $3 each. \n",
    "If John buys 5 apples and 3 oranges, and pays with a $50 bill, how much change does he get?\"\"\"\n",
    "\n",
    "# With chain of thought\n",
    "cot_prompt = \"\"\"A store sells apples for $2 each and oranges for $3 each. \n",
    "If John buys 5 apples and 3 oranges, and pays with a $50 bill, how much change does he get?\n",
    "\n",
    "Let's solve this step by step:\"\"\"\n",
    "\n",
    "display_comparison(direct_prompt, cot_prompt, \"Direct Answer\", \"Chain of Thought\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Takeaway**: Adding \"Let's solve this step by step\" or similar phrases encourages the model to show its reasoning process, which often leads to more accurate answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Few-Shot Chain of Thought\n",
    "\n",
    "Combining few-shot learning with chain of thought for complex reasoning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few-shot CoT example\n",
    "few_shot_cot = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant that solves problems step by step.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"\"\"Let me solve this step by step:\n",
    "1. Roger starts with 5 tennis balls\n",
    "2. He buys 2 cans of tennis balls\n",
    "3. Each can has 3 balls, so 2 cans have: 2 Ã— 3 = 6 balls\n",
    "4. Total tennis balls: 5 (initial) + 6 (new) = 11 balls\n",
    "\n",
    "Answer: Roger has 11 tennis balls.\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": \"\"\"A cafeteria has 23 apples. If they used 20 apples to make lunch \n",
    "and bought 6 more, how many apples do they have now?\"\"\"}\n",
    "]\n",
    "\n",
    "print(\"Few-Shot Chain of Thought:\")\n",
    "print(\"-\" * 80)\n",
    "response = get_completion(few_shot_cot, max_tokens=300)\n",
    "print(response)\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Takeaway**: Showing examples of step-by-step reasoning teaches the model to apply the same structured approach to new problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Self-Consistency with Chain of Thought\n",
    "\n",
    "Generate multiple reasoning paths and choose the most consistent answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = \"\"\"A farmer has 17 sheep. All but 9 die. How many sheep does the farmer have left?\n",
    "Think through this carefully step by step.\"\"\"\n",
    "\n",
    "print(\"Generating Multiple Reasoning Paths:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i in range(3):\n",
    "    print(f\"\\nAttempt {i+1}:\")\n",
    "    print(\"-\" * 80)\n",
    "    response = get_completion([{\"role\": \"user\", \"content\": problem}], temperature=0.8)\n",
    "    print(response)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"\\nNote: By generating multiple responses, we can identify the most consistent answer.\")\n",
    "print(\"This technique is particularly useful for problems with tricky wording.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Takeaway**: Self-consistency involves generating multiple reasoning paths with slightly higher temperature and selecting the most common answer. This improves reliability for complex reasoning tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Advanced Patterns <a id=\"advanced-patterns\"></a>\n",
    "\n",
    "### 6.1 Instruction Following with Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constrained_prompt = \"\"\"Write a product description for a smart water bottle.\n",
    "\n",
    "Constraints:\n",
    "- Exactly 3 sentences\n",
    "- First sentence: main benefit\n",
    "- Second sentence: key features\n",
    "- Third sentence: call to action\n",
    "- Use enthusiastic but professional tone\n",
    "- Do not use exclamation marks\n",
    "\"\"\"\n",
    "\n",
    "print(\"Response with Multiple Constraints:\")\n",
    "print(\"-\" * 80)\n",
    "response = get_completion([{\"role\": \"user\", \"content\": constrained_prompt}])\n",
    "print(response)\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Takeaway**: Multiple constraints help shape the exact output you need. Be specific and clear about each requirement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Iterative Refinement\n",
    "\n",
    "Using conversation history to refine outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial request\n",
    "conversation = [\n",
    "    {\"role\": \"user\", \"content\": \"Write a haiku about programming.\"}\n",
    "]\n",
    "\n",
    "print(\"Initial Response:\")\n",
    "print(\"-\" * 80)\n",
    "response1 = get_completion(conversation)\n",
    "print(response1)\n",
    "\n",
    "# Add to conversation and refine\n",
    "conversation.append({\"role\": \"assistant\", \"content\": response1})\n",
    "conversation.append({\"role\": \"user\", \"content\": \"Make it more technical and mention debugging.\"})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"\\nRefined Response:\")\n",
    "print(\"-\" * 80)\n",
    "response2 = get_completion(conversation)\n",
    "print(response2)\n",
    "\n",
    "# Further refinement\n",
    "conversation.append({\"role\": \"assistant\", \"content\": response2})\n",
    "conversation.append({\"role\": \"user\", \"content\": \"Add a metaphor about nature.\"})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"\\nFurther Refined Response:\")\n",
    "print(\"-\" * 80)\n",
    "response3 = get_completion(conversation)\n",
    "print(response3)\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Takeaway**: Multi-turn conversations allow iterative refinement. Each turn builds on previous context to progressively improve the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Meta-Prompting: Asking the Model to Improve Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_prompt = \"\"\"I want to ask an AI to help me write better documentation for my code.\n",
    "My current prompt is: \"Write documentation for my function.\"\n",
    "\n",
    "Please suggest an improved version of this prompt that would get better results. \n",
    "Explain why your version is better.\"\"\"\n",
    "\n",
    "print(\"Meta-Prompting - Asking AI to Improve Prompts:\")\n",
    "print(\"-\" * 80)\n",
    "response = get_completion([{\"role\": \"user\", \"content\": meta_prompt}], max_tokens=400)\n",
    "print(response)\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Takeaway**: The model can help you improve your own prompts! This technique is useful when you're not sure how to phrase a request for optimal results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Best Practices <a id=\"summary\"></a>\n",
    "\n",
    "### Key Principles of Effective Prompt Engineering\n",
    "\n",
    "1. **Be Specific**: Clearly state what you want, including format, length, and style\n",
    "2. **Provide Context**: Use system messages to set roles and expectations\n",
    "3. **Use Examples**: Few-shot learning dramatically improves consistency\n",
    "4. **Structure Your Prompts**: Use delimiters and clear sections\n",
    "5. **Control Temperature**: Adjust based on your need for creativity vs. consistency\n",
    "6. **Encourage Reasoning**: Use chain of thought for complex tasks\n",
    "7. **Iterate and Refine**: Use conversation history to progressively improve outputs\n",
    "8. **Set Constraints**: Define boundaries for length, format, tone, etc.\n",
    "\n",
    "### Best Practices for Agentic AI\n",
    "\n",
    "- **Define Clear Roles**: Each agent should have a well-defined purpose and expertise\n",
    "- **Use Consistent Formats**: Standardize input/output formats across agents\n",
    "- **Plan for Edge Cases**: Include instructions for handling unexpected inputs\n",
    "- **Monitor and Log**: Track prompt performance and iterate based on results\n",
    "- **Test Systematically**: Validate prompts across diverse scenarios\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Experiment with different prompt patterns for your use case\n",
    "- Build a library of effective prompts for common tasks\n",
    "- Measure and compare prompt performance quantitatively\n",
    "- Explore advanced techniques like prompt chaining and agent orchestration\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- [Azure AI Foundry Documentation](https://learn.microsoft.com/azure/ai-studio/)\n",
    "- [OpenAI Best Practices](https://platform.openai.com/docs/guides/prompt-engineering)\n",
    "- [Prompt Engineering Guide](https://www.promptingguide.ai/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercise\n",
    "\n",
    "Try creating your own prompts for the following scenarios:\n",
    "\n",
    "1. **Code Review Agent**: Design a prompt for an agent that reviews code and provides constructive feedback\n",
    "2. **Data Analyst Agent**: Create a prompt for analyzing sales data and providing insights\n",
    "3. **Customer Support Agent**: Build a prompt for handling customer inquiries with empathy and efficiency\n",
    "\n",
    "Use the techniques learned in this notebook to craft effective prompts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your practice code here\n",
    "# Example template:\n",
    "\n",
    "practice_prompt = [\n",
    "    {\"role\": \"system\", \"content\": \"Your system message here\"},\n",
    "    {\"role\": \"user\", \"content\": \"Your user message here\"}\n",
    "]\n",
    "\n",
    "# Uncomment to test:\n",
    "# response = get_completion(practice_prompt)\n",
    "# print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
